{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3909223-9ff5-481a-aecd-81dac0ce4a31",
   "metadata": {},
   "source": [
    " # Outline\n",
    "\n",
    " - [1-Packages](#1)\n",
    " - [2-Load Dataset](#2)\n",
    " - [&nbsp;&nbsp; 2.1-Function to load dataset](#2.1)\n",
    " - [&nbsp;&nbsp; 2.2 Load & View Dataset size](#2.2)\n",
    " - [3-Cost Function Implementation](#3)\n",
    " - [&nbsp;&nbsp;3.1-Cost function using for loop](#3.1)\n",
    " - [&nbsp;&nbsp;3.2-Cost Function using vectorization with numpy implementation](#3.2)\n",
    " - [&nbsp;&nbsp;3.3-ost Function using vectorization with Tensorflow implementation-1](#3.3)\n",
    " - [&nbsp;&nbsp;3.4-ost Function using vectorization with Tensorflow implementation-2](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57866651-9632-4372-bc82-220e965f07ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "##  1-Packages <img align=\"left\" src=\"./images/python-logo.png\"     style=\" width:40px;   \" > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9095108c-1d7c-45a6-be45-d94b45fdb5dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62af8f64-fda8-4bea-b4da-c20f5750528e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rajib\\miniconda3\\envs\\myML\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b013655-1b32-451b-b1ad-79819b7033e7",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "#  2- Load dataset <img align=\"left\" src=\"./images/dataset-logo.png\" style=\"width:50px; \">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2cee5-6946-4911-9c14-9496c4e92729",
   "metadata": {},
   "source": [
    "<a name='2.1'></a>\n",
    "\n",
    "### 2.1 Function to load datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8040bee-263f-4cc2-8eee-ed8abf0cb2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    file = open('./data/processed/small_movie_X.csv', 'rb')\n",
    "    X = loadtxt(file, delimiter=\",\")\n",
    "    num_movies, num_features = X.shape\n",
    "    \n",
    "    file = open('./data/processed/small_movie_R.csv', 'rb')\n",
    "    R = loadtxt(file, delimiter=\",\")\n",
    "    _,num_users = R.shape\n",
    "    \n",
    "    file = open('./data/processed/small_movie_Y.csv', 'rb')\n",
    "    Y = loadtxt(file, delimiter=\",\")\n",
    "    return (X, Y, R, num_movies, num_features, num_users)\n",
    "\n",
    "def load_movie_list():\n",
    "    df = pd.read_csv('./data/processed/movie_list_df.csv')\n",
    "    movie_list = df[\"title\"].to_list()\n",
    "    return(df, movie_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e8e0ba-79fa-4a4f-8326-7ec97830cc12",
   "metadata": {},
   "source": [
    "<a name=\"2.2\"></a>\n",
    "\n",
    "### 2.2 Load & View Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e2cf26-8c8c-4e4b-a6b1-06041ebcf53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (9724, 610) R (9724, 610)\n",
      "X (9724, 34)\n",
      "W (610, 34)\n",
      "b (1, 610)\n",
      "num_features 34\n",
      "num_movies 9724\n",
      "num_users 610\n"
     ]
    }
   ],
   "source": [
    "X, Y, R, num_movies, num_features, num_users = load_dataset()\n",
    "\n",
    "df, movie_list = load_movie_list()\n",
    "\n",
    "# Initialize parameters\n",
    "W = np.random.rand(num_users, num_features)\n",
    "b = np.random.rand(1, num_users)\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_movies\",   num_movies)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e8cba86-c9b7-45a1-a0b2-a42592f4b65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 3.921 / 5\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "593c6736-fc4d-4fc6-881e-e0279042bafe",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "\n",
    "# 3- Cost Function Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249835bd-2c81-4e66-a619-fa648f08c407",
   "metadata": {},
   "source": [
    "The collaborative filtering algorithm in the setting of movie\n",
    "recommendations considers a set of $n$-dimensional parameter vectors\n",
    "$\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$ and $b^{(0)},...,b^{(n_u-1)}$, where the\n",
    "model predicts the rating for movie $i$ by user $j$ as\n",
    "$y^{(i,j)} = \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)}$ . Given a dataset that consists of\n",
    "a set of ratings produced by some users on some movies, you wish to\n",
    "learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\n",
    "\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$  and $b^{(0)},...,b^{(n_u-1)}$ that produce the best fit (minimizes\n",
    "the squared error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27a485-c555-4230-b517-1d0a093f965c",
   "metadata": {},
   "source": [
    "#### Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$\n",
    "\n",
    "\n",
    "Below implementation [3.1-Cost function using for loop](#3.1) & [3.2 -Cost function using numpy](#3.2) are not recommended to train the model using tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e8e2ee-e66c-425f-8f0f-2356001489fc",
   "metadata": {},
   "source": [
    "<a name=\"3.1\"></a>\n",
    "\n",
    "## 3.1- Cost function using for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019d94bc-898c-474d-a44f-d56e3b95d926",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cofi_cost_func_for_loop(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    \n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        \n",
    "        for i in range(nm):\n",
    "            x = X[i,:]\n",
    "            y = Y[i,j]\n",
    "            r = R[i,j]\n",
    "            J += np.square(r * (np.dot(w,x) + b_j -y))\n",
    "    J = J/2\n",
    "    J += (lambda_ / 2) * (np.sum(sp.square(W)) + np.sum(np.square(X)))\n",
    "    return J\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ba0b31-27e1-4d04-8ab1-ec06362048d6",
   "metadata": {},
   "source": [
    "<a name=\"3.2\"></a>\n",
    "\n",
    "##  3.2- Cost Function using vectorization with numpy implementation <img align=\"left\" src=\"./images/numpy.png\" style=\"width:40px; \">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89376d0a-8631-4e4e-8a8e-7282e962cbc0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cofi_cost_func_numpy(X, W, b, Y, R, lambda_ ):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    # Vectorized computation of cost\n",
    "    J = (1/2) * np.sum(R * np.square(X @ W.T + b - Y))\n",
    "    \n",
    "    # Regularization term\n",
    "    reg_term = (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "    \n",
    "    # Compute cost with regularization\n",
    "    J += reg_term\n",
    "    \n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d304a3-9bee-4046-9098-5d4acbcecad3",
   "metadata": {},
   "source": [
    "<a name=\"3.3\"></a>\n",
    "\n",
    "## 3.3- Cost Function using vectorization with Tensorflow implementation-1 <img align=\"left\" src=\"./images/tf.png\" style=\"width:25px; \">\n",
    "\n",
    "\n",
    "This implementation requires more memory so below Tensorflow implementation-2 is recommended to compute cost for collaborative filtering: Both are same implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345694cb-886a-4966-bf9e-446d63f05c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_tf1(X, W, b, Y, R, lambda_):\n",
    "    # Tensorflow Variable\n",
    "    X_tf = tf.Variable(X, dtype=tf.float32)\n",
    "    W_tf = tf.Variable(W, dtype=tf.float32)\n",
    "    b_tf = tf.Variable(b, dtype=tf.float32)\n",
    "    Y_tf = tf.Variable(Y, dtype=tf.float32)\n",
    "    R_tf = tf.Variable(R, dtype=tf.float32)\n",
    "    # Cost computation\n",
    "    J = 0.5 * tf.reduce_sum(R_tf * tf.square(tf.matmul(X_tf, tf.transpose(W_tf))+ b_tf -Y_tf))\n",
    "    # Regularization term\n",
    "    reg_term = 0.5 * lambda_ * (tf.reduce_sum(tf.square(W)) + tf.reduce_sum(tf.square(X)))\n",
    "    # Compute cost with regularization\n",
    "    J += reg_term\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5a905-92e9-4ffd-8491-6e8f40e16ff5",
   "metadata": {},
   "source": [
    "<a name=\"3.4\"></a>\n",
    " \n",
    "## 3.4- Cost Function using vectorization with Tensorflow implementation-2 <img align=\"left\" src=\"./images/tf.png\" style=\"width:25px; \">\n",
    "\n",
    "Recommended Cost Function Implementation if using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01db1b4b-f3b1-4647-bf3c-7fbf27cc050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_tf2(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    # Compute cost\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e30727-f6de-4abe-b5f8-aaf34a9dc283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07380889-79a7-4cbb-830b-801db988dcdb",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "\n",
    "# 4- Learning Recomendation  <img align=\"left\" src=\"./images/film_rating.png\" style=\"width:40px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8799c1d-7071-46c2-99c5-b4e25b10a464",
   "metadata": {},
   "source": [
    "<a name=\"4.1\"> </a>\n",
    "\n",
    "## 4.1- Initialize my/user ratings for at least 10 movies\n",
    "\n",
    "\n",
    "You can choose your own ratings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe804cba-f5fa-4c1c-8092-9961cf7aef02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1290, 7294, 1345, 7292, 9373, 4830, 1521, 9225, 9290, 6401]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------------------------------------------------> This part is totally optional and for experimental purpose <------------------------------------------------------\n",
    "\n",
    "# Set seed to get consistent result for creating movie index\n",
    "np.random.seed(42)\n",
    "\n",
    "my_ratings_list_index = np.random.randint(1,9725,size=10).tolist()\n",
    "my_ratings_list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2a208d-9a85-48d3-ad6f-964e44c76eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings_list_index = [3569,6726,7571,7750,7752,7784,1182,9173,9288,9417]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0621e3a5-7b2a-4caf-8f31-0cd798d63170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of : 3569 is movie : Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Index of : 6726 is movie : Iron Man (2008)\n",
      "Index of : 7571 is movie : Thor (2011)\n",
      "Index of : 7750 is movie : Dark Knight Rises, The (2012)\n",
      "Index of : 7752 is movie : Sherlock Holmes: A Game of Shadows (2011)\n",
      "Index of : 7784 is movie : Intouchables (2011)\n",
      "Index of : 1182 is movie : Men in Black (a.k.a. MIB) (1997)\n",
      "Index of : 9173 is movie : The Devil's Candy (2015)\n",
      "Index of : 9288 is movie : Now You See Me 2 (2016)\n",
      "Index of : 9417 is movie : Underworld: Blood Wars (2016)\n"
     ]
    }
   ],
   "source": [
    "# Check the movie names\n",
    "for i in range(len(my_ratings_list_index)):\n",
    "    print(f\"Index of : {my_ratings_list_index[i]} is movie : {df.loc[my_ratings_list_index[i], 'title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2890b38-5771-49f4-b84c-b6113da26254",
   "metadata": {},
   "source": [
    "<a name=\"4.1.1\"> </a>\n",
    "\n",
    "\n",
    "### 4.1.1- Take movie ratings input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cd4004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ratings = np.zeros(num_movies)\n",
    "\n",
    "# add user ratings manually\n",
    "my_ratings[1182] = 2           # Men in Black (a.k.a. MIB) (1997)\n",
    "my_ratings[3569] = 3           # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[6726] = 5           # Iron Man (2008)\n",
    "my_ratings[7571] = 4           # Thor (2011)\n",
    "my_ratings[7750] = 5           # Dark Knight Rises, The (2012)\n",
    "my_ratings[7752] = 4           # Sherlock Holmes: A Game of Shadows (2011)\n",
    "my_ratings[7784] = 5           # Intouchables (2011)\n",
    "my_ratings[9173] = 1           # The Devil's Candy (2015)\n",
    "my_ratings[9288] = 3           # Now You See Me 2 (2016)\n",
    "my_ratings[9417] = 3           # Underworld: Blood Wars (2016)\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39692e72",
   "metadata": {},
   "source": [
    "Below cell to take different ratings inputs for the movies to experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86926b3a-eb14-47c9-8c6b-d81073c49601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------> This part is totally optional and for experimental purpose <------------------------------------------------------\n",
    "\n",
    "# Take inputs from user for rating variation:\n",
    "for i in range(len(my_ratings_list_index)):\n",
    "    while True:\n",
    "        try:\n",
    "            user_rating = int(input(f\"Enter your rating between 1 & 5 for the movie:  {df.loc[my_ratings_list_index[i], 'title']} \"))\n",
    "            if 1 <= user_rating <= 5:\n",
    "                my_ratings[my_ratings_list_index[i]] = user_rating\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid Input! Please enter a number between 1 & 5\")\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Invalid Input! Please enter a Valid Integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbee84d-4d4a-4c43-893c-f50a89e63b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New User Ratings: \n",
      "\n",
      "Rated 2.0  for movie : Men in Black (a.k.a. MIB) (1997)\n",
      "Rated 3.0  for movie : Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 5.0  for movie : Iron Man (2008)\n",
      "Rated 4.0  for movie : Thor (2011)\n",
      "Rated 5.0  for movie : Dark Knight Rises, The (2012)\n",
      "Rated 4.0  for movie : Sherlock Holmes: A Game of Shadows (2011)\n",
      "Rated 5.0  for movie : Intouchables (2011)\n",
      "Rated 1.0  for movie : The Devil's Candy (2015)\n",
      "Rated 3.0  for movie : Now You See Me 2 (2016)\n",
      "Rated 3.0  for movie : Underworld: Blood Wars (2016)\n"
     ]
    }
   ],
   "source": [
    "print(\"New User Ratings: \\n\")\n",
    "\n",
    "for i in range(len(my_ratings)):\n",
    "    if (my_ratings[i] > 0):\n",
    "        print(f'Rated {my_ratings[i]}  for movie : {df.loc[i, \"title\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79f5fa",
   "metadata": {},
   "source": [
    "<a name=\"4.1.2\"></a>\n",
    "\n",
    "### 4.1.2-  Add New Reviews/Ratings and Normalize user Ratings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da2fed",
   "metadata": {},
   "source": [
    "Preprocess data by subtracting mean rating for every movie (every row). Only include real ratings $R(i,j)=1$.\n",
    " ``[Ynorm, Ymean] = normalizeRatings(Y, R)`` normalized Y so that each movie has a rating of $0$ on average. Unrated moves then have a mean rating (0)\n",
    "Returns the mean rating in Ymean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa2980e7-2ec0-41f1-8236-2bcad47ffb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y,R):\n",
    "    Ymean = (np.sum(Y *R, axis=1) / (np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R)\n",
    "    return(Ymean, Ynorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa14fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new user ratings to Y\n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "# Add new user indiacator to matrix R\n",
    "R = np.c_[(my_ratings!=0).astype(int), R]\n",
    "\n",
    "# Normalize Y & R\n",
    "Ymean, Ynorm = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13c0af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9724, 611)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d90174e",
   "metadata": {},
   "source": [
    "# Numpy Implementation training  <img align=\"left\" src=\"./images/numpy.png\" style=\"width:45px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf0c97f",
   "metadata": {},
   "source": [
    "## Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3228b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, W, b, Y, R, lambda_):\n",
    "    \n",
    "    # Calculate error\n",
    "    error = (X @ W.T + b - Y) * R\n",
    "\n",
    "    # Calculate gradient\n",
    "    X_grad = error @ W + lambda_ * X\n",
    "    W_grad = error.T @ X + lambda_ * W\n",
    "    b_grad = np.sum(error)\n",
    "\n",
    "    return (X_grad, W_grad, b_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2702acb",
   "metadata": {},
   "source": [
    "### Clip the gradients to avoid exploding gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a59df63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradients(gradients, clip_value):\n",
    "    return [np.clip(grad, -clip_value, clip_value) for grad in gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90408a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(X, W, b, Y, R, lambda_, lr, clip_value):\n",
    "\n",
    "    X_grad, W_grad, b_grad = compute_gradient(X, W, b, Y, R, lambda_)\n",
    "    # Clip the gradient before updating\n",
    "    clipped_grad = clip_gradients([X_grad, W_grad, b_grad], clip_value)\n",
    "\n",
    "    # Update the parameters using clipped Gradients\n",
    "    X -= lr* clipped_grad[0]\n",
    "    W -= lr* clipped_grad[1]\n",
    "    b -= lr* clipped_grad[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12474506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 4973681.94 after Iteration: 0\n",
      "Training loss : 2736560.87 after Iteration: 10\n",
      "Training loss : 1472146.99 after Iteration: 20\n",
      "Training loss : 775433.19 after Iteration: 30\n",
      "Training loss : 401640.11 after Iteration: 40\n",
      "Training loss : 208604.89 after Iteration: 50\n",
      "Training loss : 114166.67 after Iteration: 60\n",
      "Training loss : 71499.96 after Iteration: 70\n",
      "Training loss : 54424.91 after Iteration: 80\n",
      "Training loss : 48221.65 after Iteration: 90\n",
      "Training loss : 45555.49 after Iteration: 100\n",
      "Training loss : 43945.79 after Iteration: 110\n",
      "Training loss : 42732.27 after Iteration: 120\n",
      "Training loss : 41701.72 after Iteration: 130\n",
      "Training loss : 40771.64 after Iteration: 140\n",
      "Training loss : 39906.21 after Iteration: 150\n",
      "Training loss : 39086.50 after Iteration: 160\n",
      "Training loss : 38302.60 after Iteration: 170\n",
      "Training loss : 37547.48 after Iteration: 180\n",
      "Training loss : 36816.98 after Iteration: 190\n",
      "Training loss : 36108.02 after Iteration: 200\n",
      "Training loss : 35418.36 after Iteration: 210\n",
      "Training loss : 34745.73 after Iteration: 220\n",
      "Training loss : 34089.82 after Iteration: 230\n",
      "Training loss : 33448.66 after Iteration: 240\n",
      "Training loss : 32822.46 after Iteration: 250\n",
      "Training loss : 32209.88 after Iteration: 260\n",
      "Training loss : 31610.71 after Iteration: 270\n",
      "Training loss : 31024.24 after Iteration: 280\n",
      "Training loss : 30449.89 after Iteration: 290\n",
      "Training loss : 29887.26 after Iteration: 300\n",
      "Training loss : 29335.84 after Iteration: 310\n",
      "Training loss : 28795.86 after Iteration: 320\n",
      "Training loss : 28266.24 after Iteration: 330\n",
      "Training loss : 27747.78 after Iteration: 340\n",
      "Training loss : 27240.12 after Iteration: 350\n",
      "Training loss : 26742.46 after Iteration: 360\n",
      "Training loss : 26254.06 after Iteration: 370\n",
      "Training loss : 25775.31 after Iteration: 380\n",
      "Training loss : 25306.21 after Iteration: 390\n",
      "Training loss : 24846.37 after Iteration: 400\n",
      "Training loss : 24395.42 after Iteration: 410\n",
      "Training loss : 23953.20 after Iteration: 420\n",
      "Training loss : 23519.91 after Iteration: 430\n",
      "Training loss : 23094.63 after Iteration: 440\n",
      "Training loss : 22677.62 after Iteration: 450\n",
      "Training loss : 22268.60 after Iteration: 460\n",
      "Training loss : 21867.76 after Iteration: 470\n",
      "Training loss : 21474.36 after Iteration: 480\n",
      "Training loss : 21088.65 after Iteration: 490\n"
     ]
    }
   ],
   "source": [
    "# Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "iteration = 500\n",
    "lambda_value = 0.1\n",
    "clip_value = 1.0\n",
    "\n",
    "# Set initial value for the parameters\n",
    "np.random.seed(1234)   # For consistent results\n",
    "X = np.random.normal(size=(num_movies, num_features))\n",
    "W = np.random.normal(size=(num_users, num_features))\n",
    "b = np.random.normal(size=(1,num_users))\n",
    "\n",
    "for iter in range(iteration):\n",
    "    update_parameters(X, W, b, Ynorm, R, lambda_value, learning_rate, clip_value)\n",
    "\n",
    "    # Compute cost periodically and log it\n",
    "    if iter % 10 == 0:\n",
    "        cost_value = cofi_cost_func_numpy(X, W, b, Ynorm, R, lambda_value)\n",
    "        print(f'Training loss : {cost_value:0.2f} after Iteration: {iter}')\n",
    "        # Print additional information (optional)\n",
    "        # print(f'X: {X[:2, :2]}, W: {W[:2, :2]}, b: {b[:, :2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee699d",
   "metadata": {},
   "source": [
    "#  Tensorflow implementation Training  <img align=\"left\" src=\"./images/tf.png\" style=\"width:45px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7003b920",
   "metadata": {},
   "source": [
    "Prepare to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "62fdf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "# Set initial parameters W,X,b and use Tensorflow Variable to track them\n",
    "tf.random.set_seed(1234)\n",
    "W = tf.Variable(tf.random.normal((num_users, num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64), name=\"X\")\n",
    "b = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float64), name=\"b\")\n",
    "\n",
    "\n",
    "#Instantiate Optimizer for gradient descent\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8cbdad",
   "metadata": {},
   "source": [
    "Trai the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6416b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss at iteration 0: 5540870.06\n",
      "Training Loss at iteration 5: 855711.36\n",
      "Training Loss at iteration 10: 554613.89\n",
      "Training Loss at iteration 15: 383891.35\n",
      "Training Loss at iteration 20: 279380.51\n",
      "Training Loss at iteration 25: 212556.76\n",
      "Training Loss at iteration 30: 166472.54\n",
      "Training Loss at iteration 35: 133095.36\n",
      "Training Loss at iteration 40: 108042.60\n",
      "Training Loss at iteration 45: 88889.39\n",
      "Training Loss at iteration 50: 74017.09\n",
      "Training Loss at iteration 55: 62325.51\n",
      "Training Loss at iteration 60: 53026.05\n",
      "Training Loss at iteration 65: 45540.56\n",
      "Training Loss at iteration 70: 39456.99\n",
      "Training Loss at iteration 75: 34459.75\n",
      "Training Loss at iteration 80: 30317.83\n",
      "Training Loss at iteration 85: 26856.20\n",
      "Training Loss at iteration 90: 23941.42\n",
      "Training Loss at iteration 95: 21470.82\n",
      "Training Loss at iteration 100: 19364.15\n",
      "Training Loss at iteration 105: 17558.47\n",
      "Training Loss at iteration 110: 16003.36\n",
      "Training Loss at iteration 115: 14658.32\n",
      "Training Loss at iteration 120: 13490.53\n",
      "Training Loss at iteration 125: 12473.17\n",
      "Training Loss at iteration 130: 11584.15\n",
      "Training Loss at iteration 135: 10805.09\n",
      "Training Loss at iteration 140: 10120.66\n",
      "Training Loss at iteration 145: 9517.90\n",
      "Training Loss at iteration 150: 8985.88\n",
      "Training Loss at iteration 155: 8515.28\n",
      "Training Loss at iteration 160: 8098.16\n",
      "Training Loss at iteration 165: 7727.71\n",
      "Training Loss at iteration 170: 7398.08\n",
      "Training Loss at iteration 175: 7104.23\n",
      "Training Loss at iteration 180: 6841.79\n",
      "Training Loss at iteration 185: 6607.00\n",
      "Training Loss at iteration 190: 6396.57\n",
      "Training Loss at iteration 195: 6207.63\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "\n",
    "for iter in range(iterations):\n",
    "\n",
    "    # Using TensorFlow's GradientTape to record the operations used to compute the cost\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        # Compute cost value using cost function\n",
    "        cost_value = cofi_cost_func_tf2(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Using Gradient tape to automatically retrieve the gradients of the variables with respect to the loss\n",
    "    grads = tape.gradient(cost_value,[X, W, b])\n",
    "\n",
    "    # Run One step of gradient descent by updating the value of the variables to minimize the loss\n",
    "    optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "\n",
    "    # Log the training loss periodically\n",
    "    if iter % 5 ==0:\n",
    "        print(f'Training Loss at iteration {iter}: {cost_value:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c43307",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2e3694a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 5.22 for movie Usual Suspects, The (1995)\n",
      "Predicting rating 4.99 for movie Lesson Faust (1994)\n",
      "Predicting rating 4.97 for movie Odd Life of Timothy Green, The (2012)\n",
      "Predicting rating 4.97 for movie Assignment, The (1997)\n",
      "Predicting rating 4.96 for movie Mephisto (1981)\n",
      "Predicting rating 4.96 for movie Thin Line Between Love and Hate, A (1996)\n",
      "Predicting rating 4.96 for movie Advise and Consent (1962)\n",
      "Predicting rating 4.96 for movie Monster Squad, The (1987)\n",
      "Predicting rating 4.96 for movie Galaxy of Terror (Quest) (1981)\n",
      "Predicting rating 4.96 for movie Alien Contamination (1980)\n",
      "Predicting rating 4.96 for movie Raise Your Voice (2004)\n",
      "Predicting rating 4.96 for movie Jump In! (2007)\n",
      "Predicting rating 4.96 for movie Last Hurrah for Chivalry (Hao xia) (1979)\n",
      "Predicting rating 4.96 for movie Max Manus (2008)\n",
      "Predicting rating 4.95 for movie The Girl with All the Gifts (2016)\n",
      "Predicting rating 4.95 for movie Ugly Duckling and Me!, The (2006)\n",
      "Predicting rating 4.95 for movie Love Exposure (Ai No Mukidashi) (2008)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 2.0, Predicted 2.14 for Men in Black (a.k.a. MIB) (1997)\n",
      "Original 3.0, Predicted 3.04 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 5.0, Predicted 4.83 for Iron Man (2008)\n",
      "Original 4.0, Predicted 3.87 for Thor (2011)\n",
      "Original 5.0, Predicted 4.82 for Dark Knight Rises, The (2012)\n",
      "Original 4.0, Predicted 3.95 for Sherlock Holmes: A Game of Shadows (2011)\n",
      "Original 5.0, Predicted 4.85 for Intouchables (2011)\n",
      "Original 1.0, Predicted 1.19 for The Devil's Candy (2015)\n",
      "Original 3.0, Predicted 3.28 for Now You See Me 2 (2016)\n",
      "Original 3.0, Predicted 2.98 for Underworld: Blood Wars (2016)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movie_list[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movie_list[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9dc09",
   "metadata": {},
   "source": [
    "#####  Numpy prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd6ea835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 18.79 for movie On the Beach (1959)\n",
      "Predicting rating 17.39 for movie McCabe & Mrs. Miller (1971)\n",
      "Predicting rating 17.15 for movie Crime and Punishment in Suburbia (2000)\n",
      "Predicting rating 16.79 for movie Room for Romeo Brass, A (1999)\n",
      "Predicting rating 16.60 for movie Bring Me the Head of Alfredo Garcia (1974)\n",
      "Predicting rating 16.47 for movie Fool's Gold (2008)\n",
      "Predicting rating 16.35 for movie Funny Games U.S. (2007)\n",
      "Predicting rating 16.15 for movie Carrie (2002)\n",
      "Predicting rating 16.05 for movie Digimon: The Movie (2000)\n",
      "Predicting rating 15.81 for movie Camille (1936)\n",
      "Predicting rating 15.68 for movie Jimmy Hollywood (1994)\n",
      "Predicting rating 15.65 for movie Sunshine State (2002)\n",
      "Predicting rating 15.63 for movie Freshman, The (1925)\n",
      "Predicting rating 15.53 for movie Last King of Scotland, The (2006)\n",
      "Predicting rating 15.50 for movie Perfect Sense (2011)\n",
      "Predicting rating 15.44 for movie Defiance (2008)\n",
      "Predicting rating 15.24 for movie Side Effects (2013)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 2.0, Predicted 1.98 for Men in Black (a.k.a. MIB) (1997)\n",
      "Original 3.0, Predicted 3.06 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 5.0, Predicted 4.88 for Iron Man (2008)\n",
      "Original 4.0, Predicted 3.97 for Thor (2011)\n",
      "Original 5.0, Predicted 5.07 for Dark Knight Rises, The (2012)\n",
      "Original 4.0, Predicted 3.95 for Sherlock Holmes: A Game of Shadows (2011)\n",
      "Original 5.0, Predicted 4.97 for Intouchables (2011)\n",
      "Original 1.0, Predicted 0.99 for The Devil's Candy (2015)\n",
      "Original 3.0, Predicted 2.99 for Now You See Me 2 (2016)\n",
      "Original 3.0, Predicted 2.99 for Underworld: Blood Wars (2016)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(X, np.transpose(W)) + b\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = np.argsort(-my_predictions)\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movie_list[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movie_list[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc60a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
